{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA by hand "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amandae/anaconda3/envs/nibeta/lib/python3.6/site-packages/ipykernel_launcher.py:14: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \n",
      "/home/amandae/anaconda3/envs/nibeta/lib/python3.6/site-packages/ipykernel_launcher.py:15: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\n",
    "    filepath_or_buffer='https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', \n",
    "    header=None, sep=',')\n",
    "\n",
    "df.columns=['sepal_len', 'sepal_wid', 'petal_len', 'petal_wid', 'class']\n",
    "df.dropna(how=\"all\", inplace=True) # drops the empty line at file-end\n",
    "\n",
    "df.tail()\n",
    "\n",
    "# split data table into data X and class labels y\n",
    "\n",
    "X = df.ix[:,0:4].values\n",
    "y = df.ix[:,4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Standardize data\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "X_std = StandardScaler().fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance matrix \n",
      "[[ 1.00671141 -0.11010327  0.87760486  0.82344326]\n",
      " [-0.11010327  1.00671141 -0.42333835 -0.358937  ]\n",
      " [ 0.87760486 -0.42333835  1.00671141  0.96921855]\n",
      " [ 0.82344326 -0.358937    0.96921855  1.00671141]]\n"
     ]
    }
   ],
   "source": [
    "# 2) covariance matrix\n",
    "# dimension d x d (d = # of features)\n",
    "\n",
    "cov_mat = np.cov(X_std.T) # mean_vec = np.mean(X_std, axis=0); cov_mat = (X_std - mean_vec).T.dot((X_std - mean_vec)) / (X_std.shape[0]-1)\n",
    "print('Covariance matrix \\n%s' %cov_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,)\n",
      "(4, 4)\n",
      "(4, 4)\n",
      "(4,)\n",
      "(4, 4)\n"
     ]
    }
   ],
   "source": [
    "# 3) eigendecomposition or SVD\n",
    "\n",
    "# each column is an eigenvector\n",
    "\n",
    "eig_vals, eig_vecs = np.linalg.eig(cov_mat)\n",
    "u, s, v = np.linalg.svd(cov_mat)\n",
    "\n",
    "print(eig_vals.shape)\n",
    "print(eig_vecs.shape)\n",
    "print(u.shape)\n",
    "print(s.shape)\n",
    "print(v.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of these approaches yield the same eigenvectors and eigenvalue pairs:\n",
    "\n",
    "* Eigendecomposition of the covariance matrix after standardizing the data.\n",
    "* Eigendecomposition of the correlation matrix.\n",
    "* Eigendecomposition of the correlation matrix after standardizing the data.\n",
    "\n",
    "\n",
    "\n",
    "* Eigenvectors only define the *directions* of the new axis, since they all have the same unit length 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ev in range(len(eig_vecs)):\n",
    "    np.testing.assert_array_almost_equal(1.0, np.linalg.norm(eig_vecs[:,ev]))\n",
    "    # np.sum(np.square(ev))\n",
    "print('Eigevectors all have unit length 1!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Sort pairs from highest to lowest\n",
    "\n",
    "eig_pairs = [(np.abs(eig_vals[i]), eig_vecs[:,i]) for i in range(len(eig_vals))]\n",
    "eig_pairs.sort()\n",
    "eig_pairs.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Explained variance\n",
    "\n",
    "tot  = sum(eig_vals)\n",
    "var_exp = [(i / tot)*100 for i in sorted(eig_vals, reverse=True)]\n",
    "cum_var_exp = np.cumsum(var_exp)\n",
    "\n",
    "plt.bar(['PC %s' %i for i in range(1,5)], var_exp)\n",
    "plt.plot(['PC %s' %i for i in range(1,5)], cum_var_exp, color='r')\n",
    "plt.scatter(['PC %s' %i for i in range(1,5)], cum_var_exp, color='r')\n",
    "plt.title('Explained variance')\n",
    "plt.ylabel('Explained variance (%)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Projection matrix \n",
    "# matrix of concatenated top k eigenvectors\n",
    "# projection matrix = W = d x k\n",
    "\n",
    "W = np.hstack((eig_pairs[0][1].reshape(4,1),\n",
    "              eig_pairs[1][1].reshape(4,1)))\n",
    "              \n",
    "print(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Transform data\n",
    "\n",
    "Y = X_std.dot(W)  # Y = X * W\n",
    "\n",
    "\n",
    "fig = plt.figure(1, figsize=(8, 6))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.scatter(Y[:, 0], Y[:, 1], c=iris.target, cmap=plt.cm.jet, edgecolor='k', s=50)\n",
    "ax.set_title(\"First 2 PCA directions\")\n",
    "ax.set_xlabel(\"1st eigenvector\")\n",
    "ax.set_xticklabels([])\n",
    "ax.set_ylabel(\"2nd eigenvector\")\n",
    "ax.set_yticklabels([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD\n",
    "\n",
    "https://blog.statsbot.co/singular-value-decomposition-tutorial-52c695315254\n",
    "\n",
    "* A = U * S * V.T\n",
    "* A = m * n \n",
    "* u = m * n orthogonal matrix\n",
    "* s = n * n diagonal matrix (if n < m)\n",
    "* v = n * n orthogonal matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.random.randn(4,3)\n",
    "U, S, V = np.linalg.svd(A) # V here is V.T such that A = U*S*V\n",
    "U = U[:,:-1] # where does the extra column come from?!?!?!?!?\n",
    "ss = np.diag(S)\n",
    "aa = np.dot(np.dot(U,ss),V)\n",
    "np.testing.assert_array_almost_equal(A, aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_array_almost_equal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
